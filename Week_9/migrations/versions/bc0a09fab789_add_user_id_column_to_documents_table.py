"""Add user_id column to documents table

Revision ID: bc0a09fab789
Revises: 77d18254d68d
Create Date: 2025-09-11 17:02:32.235751
"""

from alembic import op
import sqlalchemy as sa
from sqlalchemy.sql import table, column

# revision identifiers, used by Alembic.
revision = "bc0a09fab789"
down_revision = "77d18254d68d"
branch_labels = None
depends_on = None


def upgrade():
    # Drop old unused tables (autogenerated)
    op.drop_table("product_embeddings_lc")
    op.drop_table("product_embeddings")
    op.drop_table("langchain_pg_embedding")
    op.drop_table("langchain_pg_collection")

    # Step 1: Add column as nullable first
    with op.batch_alter_table("documents", schema=None) as batch_op:
        batch_op.add_column(sa.Column("user_id", sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, "users", ["user_id"], ["id"])

    # Step 2: Fill existing rows with default user_id (assuming user with id=1 exists)
    documents = table("documents", column("user_id", sa.Integer))
    op.execute(documents.update().values(user_id=1))

    # Step 3: Alter column to be NOT NULL
    with op.batch_alter_table("documents", schema=None) as batch_op:
        batch_op.alter_column("user_id", nullable=False)


def downgrade():
    with op.batch_alter_table("documents", schema=None) as batch_op:
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.drop_column("user_id")

    op.create_table(
        "langchain_pg_collection",
        sa.Column("name", sa.VARCHAR(), nullable=True),
        sa.Column("cmetadata", sa.JSON(), nullable=True),
        sa.Column("uuid", sa.UUID(), nullable=False),
        sa.PrimaryKeyConstraint("uuid", name="langchain_pg_collection_pkey"),
    )
    op.create_table(
        "langchain_pg_embedding",
        sa.Column("collection_id", sa.UUID(), nullable=True),
        sa.Column(
            "embedding", sa.VARCHAR(), nullable=True
        ),  # adjust if pgvector was used
        sa.Column("document", sa.VARCHAR(), nullable=True),
        sa.Column("cmetadata", sa.JSON(), nullable=True),
        sa.Column("custom_id", sa.VARCHAR(), nullable=True),
        sa.Column("uuid", sa.UUID(), nullable=False),
        sa.ForeignKeyConstraint(
            ["collection_id"],
            ["langchain_pg_collection.uuid"],
            name="langchain_pg_embedding_collection_id_fkey",
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("uuid", name="langchain_pg_embedding_pkey"),
    )
    op.create_table(
        "product_embeddings",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("product_id", sa.INTEGER(), nullable=True),
        sa.Column("chunk_index", sa.INTEGER(), nullable=False),
        sa.Column("text", sa.TEXT(), nullable=False),
        sa.Column(
            "embedding", sa.VARCHAR(), nullable=True
        ),  # adjust if pgvector was used
        sa.Column(
            "created_at",
            sa.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=True,
        ),
        sa.ForeignKeyConstraint(
            ["product_id"],
            ["products.product_id"],
            name="product_embeddings_product_id_fkey",
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("id", name="product_embeddings_pkey"),
        sa.UniqueConstraint("product_id", "chunk_index", name="unique_product_chunk"),
    )
    op.create_table(
        "product_embeddings_lc",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("document", sa.TEXT(), nullable=False),
        sa.Column("embedding", sa.VARCHAR(), nullable=False),
        sa.Column("metadata", sa.JSON(), nullable=True),
        sa.PrimaryKeyConstraint("id", name="product_embeddings_lc_pkey"),
    )
